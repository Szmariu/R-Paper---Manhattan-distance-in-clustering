---
title: "In defence of Manhattan Distance - on the performance impact of distance measures in clustering analisys"
author: "Michał Szałański"
date: "10 lutego 2019"
output: html_document
---

# Introduction
## Goal of the paper


## Theoretical background
### Euclidian distance

The **euclidian distance** is "straght line" distance, calcualted as a square root of a sum of squared differences beetwen each axis.   

```{r, echo=FALSE, out.width = "500px", fig.align = "center"}
knitr::include_graphics("assets/euclidian.svg")
```

*The equation for the euclidian distance. Source: Wikipedia*

### Manhattan distance
The **manhatan distance** is calculated as a sum of unsigned lengths on each axis. Because it uses modulus instead of exponenciation and rooting, it is said to be more roboust to outliers. Aditionally, because modulus is much faster to compute than exponenciation and square rooting, it may give a performance increase in certain applications.
 
```{r, echo=FALSE, out.width = "300px", fig.align = "center"}
knitr::include_graphics("assets/Manhattan_distance.svg")
```
 
*Red, blue and yellow lines represent same dsitances in the manhattan geometry, and the green line represents the euclidian distance. Source: Wikipedia*

### Canberra distance
Canberra distance is a weighted version of the manhattan distance. It is much more robust to outliers than other metrics, but is very sensible to values around 0. This feature makes it a good tool to detect some kinds of outliers. It is used mostly in spam detection software. Since it's more complex than manhattan distance, it may be slower in some applications.

```{r, echo=FALSE, out.width = "200px", fig.align = "center"}
knitr::include_graphics("assets/canberra.svg")
```

*The equation for the canberra distance. Source: Wikipedia*

# Dataset overview

## Libraries
```{r, message = FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(cluster)
library(factoextra)
library(flexclust)
library(fpc)
library(clustertend)
library(ClusterR)
library(NbClust)
library(microbenchmark)
library(multcomp)
library(knitr)

options(scipen=999) #avoiding e10 notation
```

## Importing datasets
This data was cleaned and prepared as a part of an another project. The source is [Kaggle](https://www.kaggle.com/lava18/google-play-store-apps), and it's a scrapping of a sample of Google Play Store apps.

```{r}
# Importing main data table, NaN are ommited (about 10% of all data)
mainTable <- na.omit(read.csv("data/clean_googleplaystore.csv",header=TRUE))

# Import the ratings, NaN are ommited (about 30% of all data)
ratingsTable <- na.omit(read.csv("data/clean_googleplaystore_user_reviews.csv",header=TRUE))
```

## Data overview
After loading the dataset, we can look at it's shape.
```{r}
dim(mainTable)
```

The data consists of 7 671 observations and 11 variables. Overall, this gives us 84 381 data points.

Next, we can see what are the variables in this dataset.   
```{r}
str(mainTable)
```

There are 11 columns, 5 of them are continous, the rest are factors. We'll focus on the continous variables, since they are the easies to cluster.

We can take a look at a summary of the continous variables.  
```{r}
summary(mainTable[,c(2,3,4,7,11)])
```

The ratings count, app size and price variables have some seroius outliers, but this shouldn't affect the results of performance analisys in any significant way. 

# Empyrical study
## Data preparation

First, we want to extract the two variables that we'll be working on - average rating, and number of reviews.

```{r}
clusteringData <- mainTable[,c(2,3)]
dim(clusteringData)
```

Then, we run NbClust to find a optimal number of clusters. Since our main goal is to evaluate performance, the number of clusters will stay the same for different clustering methods, and distance metrics.

```{r, optimal number of clusters, cache = TRUE}
c3<-NbClust(clusteringData , distance="euclidean", min.nc=2, max.nc=8, method="complete", index="ch")
c3$Best.nc
```

It turns out, that for this data, the optimal number of clusters is 6. 

## First perfomance comparison - distance metrics
### Sample distance matrix
Since we want to compare performance of different metrics, the most significant diferences should occour when calculating the distance matrixes. This will allow to ignore other factors, such as the implementation of different metrics in the clustering algorithms (we'll get back to that later).

```{r, sample distance matrix, cache = TRUE}
head(dist(clusteringData, method = "euclidean"))
```

### Performance evaluation
Here, I'm using the microbenrchmark function from microbenchmark package to calculate distance matrixes, each one 200 times. The result is a table containing the times for each run. Microbenchmark is a great tool for this application, because it's optimised to exclude any overhead, such as checking system time. Authors claim that it can record differences on the scale of nanoseconds. 

```{r, cache = TRUE}
timeDistanceMatrix <- microbenchmark(
  dist(clusteringData, method = "euclidean"),
  dist(clusteringData, method = "manhattan"),
  dist(clusteringData, method = "canberra"),
  dist(clusteringData, method = "minkowski"),
  times=200)
```

### Results
One we run the tests, we can display the results in a table format, and as a graph.

```{r, results='hide'}
timeDistanceMatrix$expr <- revalue(timeDistanceMatrix$expr, c('dist(clusteringData, method = "euclidean")' = "Euclidian",
                                          'dist(clusteringData, method = "manhattan")' = "Manhattan",
                                          'dist(clusteringData, method = "canberra")' = 'Canberra',
                                          'dist(clusteringData, method = "minkowski")' = 'Minkowski'))
timeDistanceMatrixResults <- print(timeDistanceMatrix, unit = "s", order = 'mean', signif = 3)
```

```{r, fig.align='center'}
kable(timeDistanceMatrixResults)
ggplot2::autoplot(timeDistanceMatrix)
```


- Tutaj interpretacja -

### Investigating the outliers - how are they distributed?

From the graph above, we can see that there are some outliers in each method. Maybe these are the first runs, after which the dist() function does some caching or other optimisation? To test this, we can look at the times 
 
```{r, fig.align='center'}
timeDistanceMatrix %>% 
  filter(timeDistanceMatrix$expr == 'Euclidian') %>% 
  droplevels.data.frame() %>%
  ggplot(aes(y=time, x=c(1:200))) + geom_point()
```

## Second perfomance comparison - CClust
### Performance evaluation

```{r, cache = TRUE}
timeCClust <- microbenchmark(
  cclust(clusteringData, k = 6, dist = "euclidean", simple = FALSE, save.data=TRUE),
  cclust(clusteringData, k = 6, dist = "manhattan", simple = FALSE, save.data=TRUE),
  times=10)
```

### Results

```{r}
timeCClustResults <- print(timeCClust, unit = "s", order = 'mean', signif = 3)
ggplot2::autoplot(timeCClust)
```

## Second perfomance comparison - Clara

### Sample clustering in Clara
```{r}
sampleClara<-clara(clusteringData, 6, metric="euclidean", stand=FALSE, samples=50,
                   sampsize=200, trace=0, medoids.x=TRUE,
                   rngR=TRUE, pamLike=FALSE, correct.d=TRUE) #cluster::
fviz_cluster(sampleClara, ellipse.type = "t", geom = "point", pointsize = 1 )
fviz_silhouette(sampleClara)
```

### Performance evaluation

```{r, cache = TRUE}
timeClara <- microbenchmark(
  clara(clusteringData, 6, metric="euclidean", stand=FALSE, samples=50,
        sampsize=200, trace=0, medoids.x=TRUE,
        rngR=TRUE, pamLike=FALSE, correct.d=TRUE),
  clara(clusteringData, 6, metric="manhattan", stand=FALSE, samples=50,
        sampsize=200, trace=0, medoids.x=TRUE,
        rngR=TRUE, pamLike=FALSE, correct.d=TRUE),
  times=100)
```

### Results

```{r}
timeClaraResults <- print(timeClara, unit = "s", order = 'mean', signif = 3)
ggplot2::autoplot(timeClara)
```

### T-test

```{r}
x <- timeClara %>% filter(timeClara$expr == 'clara(clusteringData, 6, metric = "euclidean", stand = FALSE,      samples = 50, sampsize = 200, trace = 0, medoids.x = TRUE,      rngR = TRUE, pamLike = FALSE, correct.d = TRUE)')
y <- timeClara %>% filter(timeClara$expr != 'clara(clusteringData, 6, metric = "euclidean", stand = FALSE,      samples = 50, sampsize = 200, trace = 0, medoids.x = TRUE,      rngR = TRUE, pamLike = FALSE, correct.d = TRUE)')
t.test(x$time,y$time)
```


## What about (ten algo który nie działa)

## References
