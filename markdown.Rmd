---
title: "In defence of Manhattan Distance - on the performance impact of distance measures in clustering analisys"
author: "Michał Szałański"
date: "10 lutego 2019"
output: html_document
---

## Introduction
### Euclidian distance

The **euclidian distance** is "straght line" distance, calcualted as a square root of a sum of squared differences beetwen each axis.   

```{r, echo=FALSE, out.width = "500px", fig.align = "center"}
knitr::include_graphics("assets/euclidian.svg")
```

*The equation for the euclidian distance. Source: Wikipedia*

### Manhattan distance
The **manhatan distance** is calculated as a sum of unsigned lengths on each axis. Because it uses modulus instead of exponenciation and rooting, it is said to be more roboust to outliers. Aditionally, because modulus is much faster to compute than exponenciation and square rooting, it may give a performance increase in certain applications.
 
```{r, echo=FALSE, out.width = "300px", fig.align = "center"}
knitr::include_graphics("assets/Manhattan_distance.svg")
```
 
*Red, blue and yellow lines represent same dsitances in the manhattan geometry, and the green line represents the euclidian distance. Source: Wikipedia*

### Canberra distance
Canberra distance is a weighted version of the manhattan distance. It is much more robust to outliers than other metrics, but is very sensible to values around 0. This feature makes it a good tool to detect some kinds of outliers.

```{r, echo=FALSE, out.width = "200px", fig.align = "center"}
knitr::include_graphics("assets/canberra.svg")
```

*The equation for the canberra distance. Source: Wikipedia*

## Dataset overview

Before we can import the data set, we have to load the required libraries.

```{r, message = FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(cluster)
library(factoextra)
library(flexclust)
library(fpc)
library(clustertend)
library(ClusterR)
library(NbClust)
library(microbenchmark)
library(multcomp)

options(scipen=999) #avoiding e10 notation
```


This data was cleaned and prepared as a part of an another project. The source is [Kaggle]<https://www.kaggle.com/lava18/google-play-store-apps>.

```{r}
# Importing main data table, NaN are ommited (about 10% of all data)
mainTable <- na.omit(read.csv("data/clean_googleplaystore.csv",header=TRUE))

# Import the ratings, NaN are ommited (about 30% of all data)
ratingsTable <- na.omit(read.csv("data/clean_googleplaystore_user_reviews.csv",header=TRUE))
```


After loading the dataset, we can look at it's shape.

```{r}
# Some basic summary
dim(mainTable)
```

The data consists of 7 671 observations and 11 variables.

We can take a look at
```{r}
# Some basic summary
str(mainTable)
```




```{r}
# Some basic summary
summary(mainTable)
```


## Empyrical study

### Data preparation

First, we want to extract the two variables that we'll be working on - average rating, and number of reviews.

```{r}
clusteringData <- mainTable[,c(2,3)]
dim(clusteringData)
```

Then, we run NbClust to find a optimal number of clusters. Since our main goal is to evaluate performance, the number of clusters will stay the same for different clustering methods, and distance metrics.

```{r, optimal number of clusters, cache = TRUE}
c3<-NbClust(clusteringData , distance="euclidean", min.nc=2, max.nc=8, method="complete", index="ch")
c3$Best.nc
```

It turns out, that for this data, the optimal number of clusters is 6. 

## First perfomance comparison - distance metrics
### Sample distance matrix
Since we want to compare performance of different metrics, the most significant diferences should occour when calculating the distance matrixes. This will allow to ignore other factors, such as the implementation of different metrics in the clustering algorithms (we'll get back to that later).

```{r, sample distance matrix, cache = TRUE}
head(dist(clusteringData, method = "euclidean"))
```

### Performance evaluation
Here, I'm using the microbenrchmark function from microbenchmark package to calculate distance matrixes, each 200 times. The result is a table containing the times for each run. Microbenchmark is great for this application, because it's optimised to exclude any overhead, such as checking system time. Authors claim that it can record differences on the scale of nanoseconds. 

```{r, cache = TRUE}
timeDistanceMatrix <- microbenchmark(
  dist(clusteringData, method = "euclidean"),
  dist(clusteringData, method = "manhattan"),
  dist(clusteringData, method = "canberra"),
  dist(clusteringData, method = "minkowski"),
  times=200)
```

### Results
One we run the tests, we can display the results in a table format, and as a graph.

```{r}
timeDistanceMatrixResults <- print(timeDistanceMatrix, unit = "s")
ggplot2::autoplot(timeDistanceMatrix)
```

- Tutaj interpretacja -

### Investigating the outliers - evenly distributed ?

```{r}
timeDistanceMatrix %>% 
  filter(timeDistanceMatrix$expr == 'dist(clusteringData, method = "euclidean")') %>% 
  droplevels.data.frame() %>%
  ggplot(aes(y=time, x=c(1:200))) + geom_point()
```

  ###### Comparing the speed in CClust ######

```{r, cache = TRUE}
timeCClust <- microbenchmark(
  cclust(clusteringData, k = 6, dist = "euclidean", simple = FALSE, save.data=TRUE),
  cclust(clusteringData, k = 6, dist = "manhattan", simple = FALSE, save.data=TRUE),
  times=10)
```


```{r}
timeCClustResults <- print(timeCClust, unit = "s")
ggplot2::autoplot(timeCClust)
```

   #### Comparing the speed in Clara ######
# Sample clustering
```{r}
sampleClara<-clara(clusteringData, 6, metric="euclidean", stand=FALSE, samples=50,
                   sampsize=200, trace=0, medoids.x=TRUE,
                   rngR=TRUE, pamLike=FALSE, correct.d=TRUE) #cluster::
fviz_cluster(sampleClara, ellipse.type = "t", geom = "point", pointsize = 1 )
fviz_silhouette(sampleClara)
```

# Speed test

```{r, cache = TRUE}
timeClara <- microbenchmark(
  clara(clusteringData, 6, metric="euclidean", stand=FALSE, samples=50,
        sampsize=200, trace=0, medoids.x=TRUE,
        rngR=TRUE, pamLike=FALSE, correct.d=TRUE),
  clara(clusteringData, 6, metric="manhattan", stand=FALSE, samples=50,
        sampsize=200, trace=0, medoids.x=TRUE,
        rngR=TRUE, pamLike=FALSE, correct.d=TRUE),
  times=100)
```

```{r}
timeClaraResults <- print(timeClara, unit = "s", order = 'mean', signif = 3)
ggplot2::autoplot(timeClara)
```

# T test

```{r}
x <- timeClara %>% filter(timeClara$expr == 'clara(clusteringData, 6, metric = "euclidean", stand = FALSE,      samples = 50, sampsize = 200, trace = 0, medoids.x = TRUE,      rngR = TRUE, pamLike = FALSE, correct.d = TRUE)')
y <- timeClara %>% filter(timeClara$expr != 'clara(clusteringData, 6, metric = "euclidean", stand = FALSE,      samples = 50, sampsize = 200, trace = 0, medoids.x = TRUE,      rngR = TRUE, pamLike = FALSE, correct.d = TRUE)')
t.test(x$time,y$time)
```


## What about (ten algo który nie działa)

## References










echo=FALSE
 <http://rmarkdown.rstudio.com>.

**Knit**


# This is a test 
## This is a test 
### This is a test 
#### This is a test 
##### This is a test 